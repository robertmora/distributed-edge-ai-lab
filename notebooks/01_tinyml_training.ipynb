{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11dbe01b",
   "metadata": {},
   "source": [
    "# TinyML Training → TFLite INT8 → Accuracy\n",
    "Fast training + quantization; reuse accuracy in the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf, numpy as np, os\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = (x_train.astype(\"float32\")/255.)[..., None]\n",
    "x_test  = (x_test.astype(\"float32\")/255.)[...,  None]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, 3, activation=\"relu\", input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(8, 3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "_ = model.fit(x_train, y_train, epochs=3, batch_size=256, validation_split=0.1, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"FP32 Keras accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c507f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def representative_data_gen():\n",
    "    for i in range(100):\n",
    "        idx = np.random.randint(0, len(x_train))\n",
    "        sample = x_train[idx:idx+1]\n",
    "        yield [sample.astype(np.float32)]\n",
    "\n",
    "# Full int8 quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type  = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_int8 = converter.convert()\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "open(\"models/mnist_cnn_int8.tflite\", \"wb\").write(tflite_int8)\n",
    "print(\"Saved: models/mnist_cnn_int8.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_tflite_int8(path, max_samples=2000):\n",
    "    interpreter = tf.lite.Interpreter(model_path=path)\n",
    "    interpreter.allocate_tensors()\n",
    "    in_details  = interpreter.get_input_details()\n",
    "    out_details = interpreter.get_output_details()\n",
    "    scale, zero = in_details[0][\"quantization\"]\n",
    "    correct = 0\n",
    "    N = min(max_samples, len(x_test))\n",
    "    for i in range(N):\n",
    "        x = x_test[i:i+1]\n",
    "        xq = (x/scale + zero).round().astype(np.int8)\n",
    "        interpreter.set_tensor(in_details[0]['index'], xq)\n",
    "        interpreter.invoke()\n",
    "        logits = interpreter.get_tensor(out_details[0]['index'])\n",
    "        pred = np.argmax(logits, axis=1)[0]\n",
    "        correct += (pred == y_test[i])\n",
    "    return correct / N\n",
    "\n",
    "acc_int8 = run_tflite_int8(\"models/mnist_cnn_int8.tflite\", max_samples=2000)\n",
    "print(f\"TFLite INT8 accuracy: {acc_int8:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121ca87",
   "metadata": {},
   "source": [
    "**Copy** the printed `TFLite INT8 accuracy` and paste it in the simulator notebook (cell with `set_int8_accuracy(...)`)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
